{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取文件，相对路径，文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "food_info = pandas.read_csv(\"food_info.csv\")\n",
    "print(type(food_info))#在numpy中是ndarray结构，在pandas中是dataframe结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDB_No               int64\n",
      "Shrt_Desc           object\n",
      "Water_(g)          float64\n",
      "Energ_Kcal           int64\n",
      "Protein_(g)        float64\n",
      "Lipid_Tot_(g)      float64\n",
      "Ash_(g)            float64\n",
      "Carbohydrt_(g)     float64\n",
      "Fiber_TD_(g)       float64\n",
      "Sugar_Tot_(g)      float64\n",
      "Calcium_(mg)       float64\n",
      "Iron_(mg)          float64\n",
      "Magnesium_(mg)     float64\n",
      "Phosphorus_(mg)    float64\n",
      "Potassium_(mg)     float64\n",
      "Sodium_(mg)        float64\n",
      "Zinc_(mg)          float64\n",
      "Copper_(mg)        float64\n",
      "Manganese_(mg)     float64\n",
      "Selenium_(mcg)     float64\n",
      "Vit_C_(mg)         float64\n",
      "Thiamin_(mg)       float64\n",
      "Riboflavin_(mg)    float64\n",
      "Niacin_(mg)        float64\n",
      "Vit_B6_(mg)        float64\n",
      "Vit_B12_(mcg)      float64\n",
      "Vit_A_IU           float64\n",
      "Vit_A_RAE          float64\n",
      "Vit_E_(mg)         float64\n",
      "Vit_D_mcg          float64\n",
      "Vit_D_IU           float64\n",
      "Vit_K_(mcg)        float64\n",
      "FA_Sat_(g)         float64\n",
      "FA_Mono_(g)        float64\n",
      "FA_Poly_(g)        float64\n",
      "Cholestrl_(mg)     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(food_info.dtypes)#object和numpy中string意思一样 字符值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把csv文件读进来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers:\n",
      "\n",
      "read_csv(filepath_or_buffer: Union[str, pathlib.Path, IO[~AnyStr]], sep=',', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal: str = '.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None)\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handler (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator by Python's builtin sniffer\n",
      "        tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "        different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "        will also force the use of the Python parsing engine. Note that regex\n",
      "        delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, default ``None``\n",
      "        Alias for sep.\n",
      "    header : int, list of int, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the\n",
      "        data.  Default behavior is to infer the column names: if no names\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a multi-index on the columns\n",
      "        e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : array-like, optional\n",
      "        List of column names to use. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : int, str, sequence of int / str, or False, default ``None``\n",
      "      Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
      "      string name or column index. If a sequence of int / str is given, a\n",
      "      MultiIndex is used.\n",
      "    \n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g. when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : list-like or callable, optional\n",
      "        Return a subset of the columns. If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). For example, a valid list-like\n",
      "        `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "        in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to True. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    prefix : str, optional\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    dtype : Type name or dict of column -> type, optional\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
      "        'c': 'Int64'}\n",
      "        Use `str` or `object` together with suitable `na_values` settings\n",
      "        to preserve and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    engine : {'c', 'python'}, optional\n",
      "        Parser engine to use. The C engine is faster while the python engine is\n",
      "        currently more feature-complete.\n",
      "    converters : dict, optional\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels.\n",
      "    true_values : list, optional\n",
      "        Values to consider as True.\n",
      "    false_values : list, optional\n",
      "        Values to consider as False.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like, int or callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning True if the row should be skipped and False otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : scalar, str, list-like, or dict, optional\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
      "        'nan', 'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    skip_blank_lines : bool, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values.\n",
      "    parse_dates : bool or list of int or names or list of lists or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index cannot be represented as an array of datetimes,\n",
      "        say because of an unparseable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an object data type. For\n",
      "        non-standard datetime parsing, use ``pd.to_datetime`` after\n",
      "        ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
      "        specify ``date_parser`` to be a partially-applied\n",
      "        :func:`pandas.to_datetime` with ``utc=True``. See\n",
      "        :ref:`io.csv.mixed_timezones` for more.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "        format of the datetime strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    keep_date_col : bool, default False\n",
      "        If True and `parse_dates` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If True, use a cache of unique, converted dates to apply the datetime\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "    \n",
      "        .. versionadded:: 0.25.0\n",
      "    iterator : bool, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    chunksize : int, optional\n",
      "        Return TextFileReader object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and\n",
      "        `filepath_or_buffer` is path-like, then detect compression from the\n",
      "        following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
      "        decompression). If using 'zip', the ZIP file must contain only one data\n",
      "        file to be read in. Set to None for no decompression.\n",
      "    thousands : str, optional\n",
      "        Thousands separator.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default 0\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    doublequote : bool, default ``True``\n",
      "       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        One-character string used to escape other characters.\n",
      "    comment : str, optional\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, optional\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "        `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "        override values, a ParserWarning will be issued. See csv.Dialect\n",
      "        documentation for more details.\n",
      "    error_bad_lines : bool, default True\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
      "        returned.\n",
      "    warn_bad_lines : bool, default True\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output.\n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set False, or specify the type with the `dtype` parameter.\n",
      "        Note that the entire file is read into a single DataFrame regardless,\n",
      "        use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "        (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : str, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are `None` for the ordinary converter,\n",
      "        `high` for the high-precision converter, and `round_trip` for the\n",
      "        round-trip converter.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextParser\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(pandas.read_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示头部数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDB_No</th>\n",
       "      <th>Shrt_Desc</th>\n",
       "      <th>Water_(g)</th>\n",
       "      <th>Energ_Kcal</th>\n",
       "      <th>Protein_(g)</th>\n",
       "      <th>Lipid_Tot_(g)</th>\n",
       "      <th>Ash_(g)</th>\n",
       "      <th>Carbohydrt_(g)</th>\n",
       "      <th>Fiber_TD_(g)</th>\n",
       "      <th>Sugar_Tot_(g)</th>\n",
       "      <th>...</th>\n",
       "      <th>Vit_A_IU</th>\n",
       "      <th>Vit_A_RAE</th>\n",
       "      <th>Vit_E_(mg)</th>\n",
       "      <th>Vit_D_mcg</th>\n",
       "      <th>Vit_D_IU</th>\n",
       "      <th>Vit_K_(mcg)</th>\n",
       "      <th>FA_Sat_(g)</th>\n",
       "      <th>FA_Mono_(g)</th>\n",
       "      <th>FA_Poly_(g)</th>\n",
       "      <th>Cholestrl_(mg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>BUTTER WITH SALT</td>\n",
       "      <td>15.87</td>\n",
       "      <td>717</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.368</td>\n",
       "      <td>21.021</td>\n",
       "      <td>3.043</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>BUTTER WHIPPED WITH SALT</td>\n",
       "      <td>15.87</td>\n",
       "      <td>717</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.489</td>\n",
       "      <td>23.426</td>\n",
       "      <td>3.012</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>BUTTER OIL ANHYDROUS</td>\n",
       "      <td>0.24</td>\n",
       "      <td>876</td>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3069.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.8</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>61.924</td>\n",
       "      <td>28.732</td>\n",
       "      <td>3.694</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>CHEESE BLUE</td>\n",
       "      <td>42.41</td>\n",
       "      <td>353</td>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>5.11</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>721.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>18.669</td>\n",
       "      <td>7.778</td>\n",
       "      <td>0.800</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>CHEESE BRICK</td>\n",
       "      <td>41.11</td>\n",
       "      <td>371</td>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>18.764</td>\n",
       "      <td>8.598</td>\n",
       "      <td>0.784</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NDB_No                 Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n",
       "0    1001          BUTTER WITH SALT      15.87         717         0.85   \n",
       "1    1002  BUTTER WHIPPED WITH SALT      15.87         717         0.85   \n",
       "2    1003      BUTTER OIL ANHYDROUS       0.24         876         0.28   \n",
       "3    1004               CHEESE BLUE      42.41         353        21.40   \n",
       "4    1005              CHEESE BRICK      41.11         371        23.24   \n",
       "\n",
       "   Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  ...  \\\n",
       "0          81.11     2.11            0.06           0.0           0.06  ...   \n",
       "1          81.11     2.11            0.06           0.0           0.06  ...   \n",
       "2          99.48     0.00            0.00           0.0           0.00  ...   \n",
       "3          28.74     5.11            2.34           0.0           0.50  ...   \n",
       "4          29.68     3.18            2.79           0.0           0.51  ...   \n",
       "\n",
       "   Vit_A_IU  Vit_A_RAE  Vit_E_(mg)  Vit_D_mcg  Vit_D_IU  Vit_K_(mcg)  \\\n",
       "0    2499.0      684.0        2.32        1.5      60.0          7.0   \n",
       "1    2499.0      684.0        2.32        1.5      60.0          7.0   \n",
       "2    3069.0      840.0        2.80        1.8      73.0          8.6   \n",
       "3     721.0      198.0        0.25        0.5      21.0          2.4   \n",
       "4    1080.0      292.0        0.26        0.5      22.0          2.5   \n",
       "\n",
       "   FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  \n",
       "0      51.368       21.021        3.043           215.0  \n",
       "1      50.489       23.426        3.012           219.0  \n",
       "2      61.924       28.732        3.694           256.0  \n",
       "3      18.669        7.778        0.800            75.0  \n",
       "4      18.764        8.598        0.784            94.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示尾部几行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDB_No</th>\n",
       "      <th>Shrt_Desc</th>\n",
       "      <th>Water_(g)</th>\n",
       "      <th>Energ_Kcal</th>\n",
       "      <th>Protein_(g)</th>\n",
       "      <th>Lipid_Tot_(g)</th>\n",
       "      <th>Ash_(g)</th>\n",
       "      <th>Carbohydrt_(g)</th>\n",
       "      <th>Fiber_TD_(g)</th>\n",
       "      <th>Sugar_Tot_(g)</th>\n",
       "      <th>...</th>\n",
       "      <th>Vit_A_IU</th>\n",
       "      <th>Vit_A_RAE</th>\n",
       "      <th>Vit_E_(mg)</th>\n",
       "      <th>Vit_D_mcg</th>\n",
       "      <th>Vit_D_IU</th>\n",
       "      <th>Vit_K_(mcg)</th>\n",
       "      <th>FA_Sat_(g)</th>\n",
       "      <th>FA_Mono_(g)</th>\n",
       "      <th>FA_Poly_(g)</th>\n",
       "      <th>Cholestrl_(mg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8615</th>\n",
       "      <td>90480</td>\n",
       "      <td>SYRUP CANE</td>\n",
       "      <td>26.0</td>\n",
       "      <td>269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>73.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8616</th>\n",
       "      <td>90560</td>\n",
       "      <td>SNAIL RAW</td>\n",
       "      <td>79.2</td>\n",
       "      <td>90</td>\n",
       "      <td>16.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.252</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8617</th>\n",
       "      <td>93600</td>\n",
       "      <td>TURTLE GREEN RAW</td>\n",
       "      <td>78.5</td>\n",
       "      <td>89</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.170</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NDB_No         Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n",
       "8615   90480        SYRUP CANE       26.0         269          0.0   \n",
       "8616   90560         SNAIL RAW       79.2          90         16.1   \n",
       "8617   93600  TURTLE GREEN RAW       78.5          89         19.8   \n",
       "\n",
       "      Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  \\\n",
       "8615            0.0     0.86           73.14           0.0           73.2   \n",
       "8616            1.4     1.30            2.00           0.0            0.0   \n",
       "8617            0.5     1.20            0.00           0.0            0.0   \n",
       "\n",
       "      ...  Vit_A_IU  Vit_A_RAE  Vit_E_(mg)  Vit_D_mcg  Vit_D_IU  Vit_K_(mcg)  \\\n",
       "8615  ...       0.0        0.0         0.0        0.0       0.0          0.0   \n",
       "8616  ...     100.0       30.0         5.0        0.0       0.0          0.1   \n",
       "8617  ...     100.0       30.0         0.5        0.0       0.0          0.1   \n",
       "\n",
       "      FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  \n",
       "8615       0.000        0.000        0.000             0.0  \n",
       "8616       0.361        0.259        0.252            50.0  \n",
       "8617       0.127        0.088        0.170            50.0  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_info.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示每一列的指标，列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NDB_No', 'Shrt_Desc', 'Water_(g)', 'Energ_Kcal', 'Protein_(g)',\n",
      "       'Lipid_Tot_(g)', 'Ash_(g)', 'Carbohydrt_(g)', 'Fiber_TD_(g)',\n",
      "       'Sugar_Tot_(g)', 'Calcium_(mg)', 'Iron_(mg)', 'Magnesium_(mg)',\n",
      "       'Phosphorus_(mg)', 'Potassium_(mg)', 'Sodium_(mg)', 'Zinc_(mg)',\n",
      "       'Copper_(mg)', 'Manganese_(mg)', 'Selenium_(mcg)', 'Vit_C_(mg)',\n",
      "       'Thiamin_(mg)', 'Riboflavin_(mg)', 'Niacin_(mg)', 'Vit_B6_(mg)',\n",
      "       'Vit_B12_(mcg)', 'Vit_A_IU', 'Vit_A_RAE', 'Vit_E_(mg)', 'Vit_D_mcg',\n",
      "       'Vit_D_IU', 'Vit_K_(mcg)', 'FA_Sat_(g)', 'FA_Mono_(g)', 'FA_Poly_(g)',\n",
      "       'Cholestrl_(mg)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(food_info.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8618, 36)\n"
     ]
    }
   ],
   "source": [
    "print(food_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#取数据不像python或者numpy指定索引,pandas中通过loc函数调取数据,如下调取第一行数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDB_No                         1001\n",
      "Shrt_Desc          BUTTER WITH SALT\n",
      "Water_(g)                     15.87\n",
      "Energ_Kcal                      717\n",
      "Protein_(g)                    0.85\n",
      "Lipid_Tot_(g)                 81.11\n",
      "Ash_(g)                        2.11\n",
      "Carbohydrt_(g)                 0.06\n",
      "Fiber_TD_(g)                      0\n",
      "Sugar_Tot_(g)                  0.06\n",
      "Calcium_(mg)                     24\n",
      "Iron_(mg)                      0.02\n",
      "Magnesium_(mg)                    2\n",
      "Phosphorus_(mg)                  24\n",
      "Potassium_(mg)                   24\n",
      "Sodium_(mg)                     643\n",
      "Zinc_(mg)                      0.09\n",
      "Copper_(mg)                       0\n",
      "Manganese_(mg)                    0\n",
      "Selenium_(mcg)                    1\n",
      "Vit_C_(mg)                        0\n",
      "Thiamin_(mg)                  0.005\n",
      "Riboflavin_(mg)               0.034\n",
      "Niacin_(mg)                   0.042\n",
      "Vit_B6_(mg)                   0.003\n",
      "Vit_B12_(mcg)                  0.17\n",
      "Vit_A_IU                       2499\n",
      "Vit_A_RAE                       684\n",
      "Vit_E_(mg)                     2.32\n",
      "Vit_D_mcg                       1.5\n",
      "Vit_D_IU                         60\n",
      "Vit_K_(mcg)                       7\n",
      "FA_Sat_(g)                   51.368\n",
      "FA_Mono_(g)                  21.021\n",
      "FA_Poly_(g)                   3.043\n",
      "Cholestrl_(mg)                  215\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(food_info.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NDB_No         Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n",
      "3    1004       CHEESE BLUE      42.41         353        21.40   \n",
      "4    1005      CHEESE BRICK      41.11         371        23.24   \n",
      "5    1006       CHEESE BRIE      48.42         334        20.75   \n",
      "6    1007  CHEESE CAMEMBERT      51.80         300        19.80   \n",
      "\n",
      "   Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  ...  \\\n",
      "3          28.74     5.11            2.34           0.0           0.50  ...   \n",
      "4          29.68     3.18            2.79           0.0           0.51  ...   \n",
      "5          27.68     2.70            0.45           0.0           0.45  ...   \n",
      "6          24.26     3.68            0.46           0.0           0.46  ...   \n",
      "\n",
      "   Vit_A_IU  Vit_A_RAE  Vit_E_(mg)  Vit_D_mcg  Vit_D_IU  Vit_K_(mcg)  \\\n",
      "3     721.0      198.0        0.25        0.5      21.0          2.4   \n",
      "4    1080.0      292.0        0.26        0.5      22.0          2.5   \n",
      "5     592.0      174.0        0.24        0.5      20.0          2.3   \n",
      "6     820.0      241.0        0.21        0.4      18.0          2.0   \n",
      "\n",
      "   FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  \n",
      "3      18.669        7.778        0.800            75.0  \n",
      "4      18.764        8.598        0.784            94.0  \n",
      "5      17.410        8.013        0.826           100.0  \n",
      "6      15.259        7.023        0.724            72.0  \n",
      "\n",
      "[4 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(food_info.loc[3:6])#调取的是3456行数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NDB_No             Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n",
      "2     1003  BUTTER OIL ANHYDROUS       0.24         876         0.28   \n",
      "5     1006           CHEESE BRIE      48.42         334        20.75   \n",
      "10    1011          CHEESE COLBY      38.20         394        23.76   \n",
      "\n",
      "    Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  ...  \\\n",
      "2           99.48     0.00            0.00           0.0           0.00  ...   \n",
      "5           27.68     2.70            0.45           0.0           0.45  ...   \n",
      "10          32.11     3.36            2.57           0.0           0.52  ...   \n",
      "\n",
      "    Vit_A_IU  Vit_A_RAE  Vit_E_(mg)  Vit_D_mcg  Vit_D_IU  Vit_K_(mcg)  \\\n",
      "2     3069.0      840.0        2.80        1.8      73.0          8.6   \n",
      "5      592.0      174.0        0.24        0.5      20.0          2.3   \n",
      "10     994.0      264.0        0.28        0.6      24.0          2.7   \n",
      "\n",
      "    FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  \n",
      "2       61.924       28.732        3.694           256.0  \n",
      "5       17.410        8.013        0.826           100.0  \n",
      "10      20.218        9.280        0.953            95.0  \n",
      "\n",
      "[3 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "two_five_ten = [2,5,10]#调取的是第二，五，十行数据\n",
    "print(food_info.loc[two_five_ten])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NDB_No       Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  Lipid_Tot_(g)  \\\n",
      "3     1004     CHEESE BLUE      42.41         353        21.40          28.74   \n",
      "5     1006     CHEESE BRIE      48.42         334        20.75          27.68   \n",
      "20    1021  CHEESE GJETOST      13.44         466         9.65          29.51   \n",
      "\n",
      "    Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  ...  Vit_A_IU  \\\n",
      "3      5.11            2.34           0.0           0.50  ...     721.0   \n",
      "5      2.70            0.45           0.0           0.45  ...     592.0   \n",
      "20     4.75           42.65           0.0            NaN  ...    1113.0   \n",
      "\n",
      "    Vit_A_RAE  Vit_E_(mg)  Vit_D_mcg  Vit_D_IU  Vit_K_(mcg)  FA_Sat_(g)  \\\n",
      "3       198.0        0.25        0.5      21.0          2.4      18.669   \n",
      "5       174.0        0.24        0.5      20.0          2.3      17.410   \n",
      "20      334.0         NaN        NaN       NaN          NaN      19.160   \n",
      "\n",
      "    FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  \n",
      "3         7.778        0.800            75.0  \n",
      "5         8.013        0.826           100.0  \n",
      "20        7.879        0.938            94.0  \n",
      "\n",
      "[3 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(food_info.loc[[3,5,20]])#第二种method调取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一列一列取数据，通过列名定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1001\n",
      "1        1002\n",
      "2        1003\n",
      "3        1004\n",
      "4        1005\n",
      "        ...  \n",
      "8613    83110\n",
      "8614    90240\n",
      "8615    90480\n",
      "8616    90560\n",
      "8617    93600\n",
      "Name: NDB_No, Length: 8618, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ndb_col = food_info[\"NDB_No\"]\n",
    "print(ndb_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以通过string值查询列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1001\n",
      "1        1002\n",
      "2        1003\n",
      "3        1004\n",
      "4        1005\n",
      "        ...  \n",
      "8613    83110\n",
      "8614    90240\n",
      "8615    90480\n",
      "8616    90560\n",
      "8617    93600\n",
      "Name: NDB_No, Length: 8618, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_name = \"NDB_No\"\n",
    "ndb_col = food_info[col_name]\n",
    "print(ndb_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定位两个列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Zinc_(mg)  Copper_(mg)\n",
      "0          0.09        0.000\n",
      "1          0.05        0.016\n",
      "2          0.01        0.001\n",
      "3          2.66        0.040\n",
      "4          2.60        0.024\n",
      "...         ...          ...\n",
      "8613       1.10        0.100\n",
      "8614       1.55        0.033\n",
      "8615       0.19        0.020\n",
      "8616       1.00        0.400\n",
      "8617       1.00        0.250\n",
      "\n",
      "[8618 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = [\"Zinc_(mg)\",\"Copper_(mg)\"]\n",
    "zin_copper = food_info[columns]\n",
    "print(zin_copper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第二种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Zinc_(mg)  Copper_(mg)\n",
      "0          0.09        0.000\n",
      "1          0.05        0.016\n",
      "2          0.01        0.001\n",
      "3          2.66        0.040\n",
      "4          2.60        0.024\n",
      "...         ...          ...\n",
      "8613       1.10        0.100\n",
      "8614       1.55        0.033\n",
      "8615       0.19        0.020\n",
      "8616       1.00        0.400\n",
      "8617       1.00        0.250\n",
      "\n",
      "[8618 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "zin_copper = food_info[[\"Zinc_(mg)\",\"Copper_(mg)\"]]\n",
    "print(zin_copper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查询哪些列名中以g为单位的数据，先查看列名，生成list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NDB_No', 'Shrt_Desc', 'Water_(g)', 'Energ_Kcal', 'Protein_(g)', 'Lipid_Tot_(g)', 'Ash_(g)', 'Carbohydrt_(g)', 'Fiber_TD_(g)', 'Sugar_Tot_(g)', 'Calcium_(mg)', 'Iron_(mg)', 'Magnesium_(mg)', 'Phosphorus_(mg)', 'Potassium_(mg)', 'Sodium_(mg)', 'Zinc_(mg)', 'Copper_(mg)', 'Manganese_(mg)', 'Selenium_(mcg)', 'Vit_C_(mg)', 'Thiamin_(mg)', 'Riboflavin_(mg)', 'Niacin_(mg)', 'Vit_B6_(mg)', 'Vit_B12_(mcg)', 'Vit_A_IU', 'Vit_A_RAE', 'Vit_E_(mg)', 'Vit_D_mcg', 'Vit_D_IU', 'Vit_K_(mcg)', 'FA_Sat_(g)', 'FA_Mono_(g)', 'FA_Poly_(g)', 'Cholestrl_(mg)']\n"
     ]
    }
   ],
   "source": [
    "col_names = food_info.columns.tolist()\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Water_(g)  Protein_(g)  Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  \\\n",
      "0      15.87         0.85          81.11     2.11            0.06   \n",
      "1      15.87         0.85          81.11     2.11            0.06   \n",
      "2       0.24         0.28          99.48     0.00            0.00   \n",
      "\n",
      "   Fiber_TD_(g)  Sugar_Tot_(g)  FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  \n",
      "0           0.0           0.06      51.368       21.021        3.043  \n",
      "1           0.0           0.06      50.489       23.426        3.012  \n",
      "2           0.0           0.00      61.924       28.732        3.694  \n"
     ]
    }
   ],
   "source": [
    "g_columns = []\n",
    "for c in col_names:\n",
    "    if c.endswith(\"(g)\"):\n",
    "        g_columns.append(c)\n",
    "print(food_info[g_columns].head(3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在pandas中进行加减乘除操作；例如将mg单位换成g单位；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.02\n",
      "1       0.16\n",
      "2       0.00\n",
      "3       0.31\n",
      "4       0.43\n",
      "        ... \n",
      "8613    1.40\n",
      "8614    0.58\n",
      "8615    3.60\n",
      "8616    3.50\n",
      "8617    1.40\n",
      "Name: Iron_(mg), Length: 8618, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(food_info[\"Iron_(mg)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.00002\n",
      "1       0.00016\n",
      "2       0.00000\n",
      "3       0.00031\n",
      "4       0.00043\n",
      "         ...   \n",
      "8613    0.00140\n",
      "8614    0.00058\n",
      "8615    0.00360\n",
      "8616    0.00350\n",
      "8617    0.00140\n",
      "Name: Iron_(mg), Length: 8618, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "div_1000=food_info[\"Iron_(mg)\"]/1000#将整个列的每个数据都除1000\n",
    "print(div_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对两个列进行组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_energy=food_info[\"Water_(g)\"]*food_info[\"Energ_Kcal\"]#对应位置相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#往原来的dataframe里多加一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8618, 36)\n",
      "(8618, 37)\n"
     ]
    }
   ],
   "source": [
    "iron_g=food_info[\"Iron_(mg)\"]/1000\n",
    "print(food_info.shape)\n",
    "food_info[\"Iron_(g)\"]=iron_g#首先iron_g是对原来mg/1000后的g为新的一列，并多加的这一列为Iron_(g)\n",
    "print(food_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      -59.1325\n",
      "1      -59.1325\n",
      "2      -74.0500\n",
      "3       21.2450\n",
      "4       24.2200\n",
      "         ...   \n",
      "8613    18.1750\n",
      "8614    40.4500\n",
      "8615     0.0000\n",
      "8616    31.1500\n",
      "8617    39.2250\n",
      "Length: 8618, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Score=2x(protein_(g))-0.75x(Lipid_Tot_(g))\n",
    "weighted_protein = food_info[\"Protein_(g)\"]*2\n",
    "weighted_fat = -0.75*food_info[\"Lipid_Tot_(g)\"]\n",
    "initial_rating = weighted_protein +weighted_fat\n",
    "print(initial_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最大值.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n"
     ]
    }
   ],
   "source": [
    "max_calories = food_info[\"Energ_Kcal\"].max()\n",
    "print(max_calories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#归一化操作，让每一个元素都除上最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.794900\n",
      "1       0.794900\n",
      "2       0.971175\n",
      "3       0.391353\n",
      "4       0.411308\n",
      "          ...   \n",
      "8613    0.338137\n",
      "8614    0.123060\n",
      "8615    0.298226\n",
      "8616    0.099778\n",
      "8617    0.098670\n",
      "Name: Energ_Kcal, Length: 8618, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "normalized_calories=food_info[\"Energ_Kcal\"]/max_calories\n",
    "print(normalized_calories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_protein = food_info[\"Protein_(g)\"]/food_info[\"Protein_(g)\"].max()\n",
    "normalized_fat = food_info[\"Lipid_Tot_(g)\"]/food_info[\"Lipid_Tot_(g)\"].max()\n",
    "food_info[\"Normalized_Protein\"]=normalized_protein\n",
    "food_info[\"Normalized_Fat\"]=normalized_fat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#排序操作sort_values默认从小到大升序NaN为缺失值，制定一个列，按照某个列进行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8618, 39)\n"
     ]
    }
   ],
   "source": [
    "print(food_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760     0.0\n",
      "758     0.0\n",
      "405     0.0\n",
      "761     0.0\n",
      "2269    0.0\n",
      "       ... \n",
      "8184    NaN\n",
      "8185    NaN\n",
      "8195    NaN\n",
      "8251    NaN\n",
      "8267    NaN\n",
      "Name: Sodium_(mg), Length: 8618, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "food_info.sort_values(\"Sodium_(mg)\",inplace=True)\n",
    "print(food_info[\"Sodium_(mg)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#降序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276     38758.0\n",
      "5814    27360.0\n",
      "6192    26050.0\n",
      "1242    26000.0\n",
      "1245    24000.0\n",
      "         ...   \n",
      "8184        NaN\n",
      "8185        NaN\n",
      "8195        NaN\n",
      "8251        NaN\n",
      "8267        NaN\n",
      "Name: Sodium_(mg), Length: 8618, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "food_info.sort_values(\"Sodium_(mg)\",inplace=True,ascending=False)\n",
    "print(food_info[\"Sodium_(mg)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "titanic_survival = pd.read_csv(\"titanic_train.csv\")\n",
    "titanic_survival.head()#survived只有0和1两个值，标签值，分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定位 Age这一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     22.0\n",
      "1     38.0\n",
      "2     26.0\n",
      "3     35.0\n",
      "4     35.0\n",
      "5      NaN\n",
      "6     54.0\n",
      "7      2.0\n",
      "8     27.0\n",
      "9     14.0\n",
      "10     4.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "age = titanic_survival[\"Age\"]\n",
    "print(age.loc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判断缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "886    False\n",
      "887    False\n",
      "888     True\n",
      "889    False\n",
      "890    False\n",
      "Name: Age, Length: 891, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "ageisnull=pd.isnull(age)\n",
    "print(ageisnull)#缺失值的结果是true，反之亦然"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把true/false当成是索引，结果为true的值留下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5     NaN\n",
      "17    NaN\n",
      "19    NaN\n",
      "26    NaN\n",
      "28    NaN\n",
      "       ..\n",
      "859   NaN\n",
      "863   NaN\n",
      "868   NaN\n",
      "878   NaN\n",
      "888   NaN\n",
      "Name: Age, Length: 177, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "agenulltrue=age[ageisnull]\n",
    "print(agenulltrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#缺失值数量,len函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "agenullcount = len(agenulltrue)\n",
    "print(agenullcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#求平均年龄sum/len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "mean_age=sum(titanic_survival[\"Age\"])/len(titanic_survival[\"Age\"])\n",
    "print(mean_age)#数据中有缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在计算均值前过滤缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      22.0\n",
      "1      38.0\n",
      "2      26.0\n",
      "3      35.0\n",
      "4      35.0\n",
      "       ... \n",
      "885    39.0\n",
      "886    27.0\n",
      "887    19.0\n",
      "889    26.0\n",
      "890    32.0\n",
      "Name: Age, Length: 714, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "good_ages=titanic_survival[\"Age\"][ageisnull==False]\n",
    "print(good_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "correct_mean_age=sum(good_ages)/len(good_ages)\n",
    "print(correct_mean_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas中直接调.mean()可以直接求均值，自动过滤缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "correct_mean_age=titanic_survival[\"Age\"].mean()\n",
    "print(correct_mean_age)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#求每个class船舱等级的平均价格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 84.15468749999992, 2: 20.66218315217391, 3: 13.675550101832997}\n"
     ]
    }
   ],
   "source": [
    "passenger_classes = [1,2,3]\n",
    "fares_by_class = {}\n",
    "for this_class in passenger_classes:\n",
    "    pclass_rows = titanic_survival[titanic_survival[\"Pclass\"]== this_class]#先定位到船舱类别，把一等舱数据取到\n",
    "    pclass_fares = pclass_rows[\"Fare\"]#定位到船票价格那一列\n",
    "    fare_for_class=pclass_fares.mean()#那一列的船票价格取均值\n",
    "    fares_by_class[this_class]=fare_for_class\n",
    "print(fares_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot_table数据透视表,计算各个仓位平均获救了多少人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Survived\n",
      "Pclass          \n",
      "1       0.629630\n",
      "2       0.472826\n",
      "3       0.242363\n"
     ]
    }
   ],
   "source": [
    "passenger_suvival=titanic_survival.pivot_table(index=\"Pclass\",values=\"Survived\",aggfunc=np.mean)\n",
    "print(passenger_suvival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age\n",
      "Pclass           \n",
      "1       38.233441\n",
      "2       29.877630\n",
      "3       25.140620\n"
     ]
    }
   ],
   "source": [
    "passenger_age=titanic_survival.pivot_table(index=\"Pclass\",values=\"Age\",aggfunc=np.mean)\n",
    "print(passenger_age)#计算每个舱位的平均年龄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算两个变量值，方便一起看一下关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Fare  Survived\n",
      "Embarked                      \n",
      "C         10072.2962        93\n",
      "Q          1022.2543        30\n",
      "S         17439.3988       217\n"
     ]
    }
   ],
   "source": [
    "port_stats=titanic_survival.pivot_table(index=\"Embarked\",values=[\"Fare\",\"Survived\"],aggfunc=np.sum)\n",
    "print(port_stats)#计算不同码头的船票总价格和总获救人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropna函数将指定的缺失值丢掉\n",
    "#specifying axis=1 or axis='columns'willdrop any columns that have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "885          886         0       3   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "885      5            382652  29.1250   NaN        Q  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[714 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "drop_na_columns = titanic_survival.dropna(axis=1)\n",
    "newtable=titanic_survival.dropna(axis=0,subset=[\"Age\",\"Sex\"])#维度为0，在age和sex中看缺失值\n",
    "print(newtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定位到具体值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0\n",
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "row_index_83_age=titanic_survival.loc[83,\"Age\"]\n",
    "print(row_index_83_age)#第83个（行）样本的年龄是多少\n",
    "print(titanic_survival.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "row_index_766_pclass=titanic_survival.loc[766,\"Pclass\"]\n",
    "print(row_index_766_pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#降序升序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass                                  Name  \\\n",
      "630          631         1       1  Barkworth, Mr. Algernon Henry Wilson   \n",
      "851          852         0       3                   Svensson, Mr. Johan   \n",
      "493          494         0       1               Artagaveytia, Mr. Ramon   \n",
      "96            97         0       1             Goldschmidt, Mr. George B   \n",
      "116          117         0       3                  Connors, Mr. Patrick   \n",
      "672          673         0       2           Mitchell, Mr. Henry Michael   \n",
      "745          746         0       1          Crosby, Capt. Edward Gifford   \n",
      "33            34         0       2                 Wheadon, Mr. Edward H   \n",
      "54            55         0       1        Ostby, Mr. Engelhart Cornelius   \n",
      "280          281         0       3                      Duane, Mr. Frank   \n",
      "\n",
      "      Sex   Age  SibSp  Parch      Ticket     Fare Cabin Embarked  \n",
      "630  male  80.0      0      0       27042  30.0000   A23        S  \n",
      "851  male  74.0      0      0      347060   7.7750   NaN        S  \n",
      "493  male  71.0      0      0    PC 17609  49.5042   NaN        C  \n",
      "96   male  71.0      0      0    PC 17754  34.6542    A5        C  \n",
      "116  male  70.5      0      0      370369   7.7500   NaN        Q  \n",
      "672  male  70.0      0      0  C.A. 24580  10.5000   NaN        S  \n",
      "745  male  70.0      1      1   WE/P 5735  71.0000   B22        S  \n",
      "33   male  66.0      0      0  C.A. 24579  10.5000   NaN        S  \n",
      "54   male  65.0      0      1      113509  61.9792   B30        C  \n",
      "280  male  65.0      0      0      336439   7.7500   NaN        Q  \n"
     ]
    }
   ],
   "source": [
    "new_titanic_survival=titanic_survival.sort_values(\"Age\",ascending=False)\n",
    "print(new_titanic_survival[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重置index值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_reindexed = new_titanic_survival.reset_index(drop=True)#先将原来排过序的值传过来，在resetindex一下，drop将原来的index去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PassengerId  Survived  Pclass                                  Name   Sex  \\\n",
      "0           631         1       1  Barkworth, Mr. Algernon Henry Wilson  male   \n",
      "1           852         0       3                   Svensson, Mr. Johan  male   \n",
      "2           494         0       1               Artagaveytia, Mr. Ramon  male   \n",
      "3            97         0       1             Goldschmidt, Mr. George B  male   \n",
      "4           117         0       3                  Connors, Mr. Patrick  male   \n",
      "5           673         0       2           Mitchell, Mr. Henry Michael  male   \n",
      "6           746         0       1          Crosby, Capt. Edward Gifford  male   \n",
      "7            34         0       2                 Wheadon, Mr. Edward H  male   \n",
      "8            55         0       1        Ostby, Mr. Engelhart Cornelius  male   \n",
      "9           281         0       3                      Duane, Mr. Frank  male   \n",
      "10          457         0       1             Millet, Mr. Francis Davis  male   \n",
      "\n",
      "     Age  SibSp  Parch      Ticket     Fare Cabin Embarked  \n",
      "0   80.0      0      0       27042  30.0000   A23        S  \n",
      "1   74.0      0      0      347060   7.7750   NaN        S  \n",
      "2   71.0      0      0    PC 17609  49.5042   NaN        C  \n",
      "3   71.0      0      0    PC 17754  34.6542    A5        C  \n",
      "4   70.5      0      0      370369   7.7500   NaN        Q  \n",
      "5   70.0      0      0  C.A. 24580  10.5000   NaN        S  \n",
      "6   70.0      1      1   WE/P 5735  71.0000   B22        S  \n",
      "7   66.0      0      0  C.A. 24579  10.5000   NaN        S  \n",
      "8   65.0      0      1      113509  61.9792   B30        C  \n",
      "9   65.0      0      0      336439   7.7500   NaN        Q  \n",
      "10  65.0      0      0       13509  26.5500   E38        S  \n"
     ]
    }
   ],
   "source": [
    "print(titanic_reindexed.loc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义函数,第一百行的东西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hundredth_row(column):#提取第一百行\n",
    "    hundredth_item = column.loc[99]\n",
    "    return hundredth_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回第一百行的每一列的值apply调用自定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId                  100\n",
      "Survived                       0\n",
      "Pclass                         2\n",
      "Name           Kantor, Mr. Sinai\n",
      "Sex                         male\n",
      "Age                           34\n",
      "SibSp                          1\n",
      "Parch                          0\n",
      "Ticket                    244367\n",
      "Fare                          26\n",
      "Cabin                        NaN\n",
      "Embarked                       S\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "hundredth_row=titanic_survival.apply(hundredth_row)\n",
    "print(hundredth_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定一个函数计算每一列的缺失值个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_null_count(column):\n",
    "    column_null = pd.isnull(column)\n",
    "    null=column[column_null]\n",
    "    return len(null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_null_count = titanic_survival.apply(not_null_count)\n",
    "print(column_null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用DataFrame.apply()method去迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Third Class\n",
      "1       First Class\n",
      "2       Third Class\n",
      "3       First Class\n",
      "4       Third Class\n",
      "           ...     \n",
      "886    Second Class\n",
      "887     First Class\n",
      "888     Third Class\n",
      "889     First Class\n",
      "890     Third Class\n",
      "Length: 891, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def which_class(row):\n",
    "    pclass = row['Pclass']\n",
    "    if pd.isnull(pclass):\n",
    "        return \"Unknown\"\n",
    "    elif pclass == 1:\n",
    "        return \"First Class\"\n",
    "    elif pclass == 2:\n",
    "        return \"Second Class\"\n",
    "    elif pclass == 3:\n",
    "        return \"Third Class\"\n",
    "\n",
    "classes=titanic_survival.apply(which_class,axis=1)\n",
    "print(classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将连续值离散化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "886    False\n",
      "887    False\n",
      "888    False\n",
      "889    False\n",
      "890    False\n",
      "Length: 891, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "def is_minor(row):\n",
    "    if row[\"Age\"]<18:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "minors= titanic_survival.apply(is_minor,axis=1)\n",
    "print(minors)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        adult\n",
      "1        adult\n",
      "2        adult\n",
      "3        adult\n",
      "4        adult\n",
      "        ...   \n",
      "886      adult\n",
      "887      adult\n",
      "888    unknown\n",
      "889      adult\n",
      "890      adult\n",
      "Length: 891, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def generate_age_label(row):\n",
    "    age = row[\"Age\"]\n",
    "    if pd.isnull(age):\n",
    "        return\"unknown\"\n",
    "    elif age<18:\n",
    "        return\"minor\"\n",
    "    else:\n",
    "        return\"adult\"\n",
    "\n",
    "age_labels = titanic_survival.apply(generate_age_label,axis=1)\n",
    "print(age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用透视表呈现不同年龄标签的平均获救率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Survived\n",
      "age_labels          \n",
      "adult       0.381032\n",
      "minor       0.539823\n",
      "unknown     0.293785\n"
     ]
    }
   ],
   "source": [
    "titanic_survival[\"age_labels\"]=age_labels\n",
    "age_group_survival = titanic_survival.pivot_table(index=\"age_labels\",values=\"Survived\")\n",
    "print(age_group_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Series(dataframe中的某一行或者某一列)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fandango = pd.read_csv('fandango_score_comparison.csv')\n",
    "series_film = fandango[\"FILM\"]\n",
    "print(type(series_film))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Avengers: Age of Ultron (2015)\n",
      "1                 Cinderella (2015)\n",
      "2                    Ant-Man (2015)\n",
      "3            Do You Believe? (2015)\n",
      "4     Hot Tub Time Machine 2 (2015)\n",
      "Name: FILM, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(series_film[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    74\n",
      "1    85\n",
      "2    80\n",
      "3    18\n",
      "4    14\n",
      "Name: RottenTomatoes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "series_rt = fandango[\"RottenTomatoes\"]\n",
    "print(series_rt[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "\n",
    "film_names = series_film.values#series里的值的类型是ndarray\n",
    "print(type(film_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建seires，一个电影名字对应电影评分值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 74  85  80  18  14  63  42  86  99  89  84  82  99  51  90   9  46  59\n",
      "  50  17  79  59  68  60  85  99  92  88  96  92  96  89  92  10  19  11\n",
      "  52  71  51  60  94  99  97  95  75  50  30  27   9  26  67  32  54   8\n",
      "  71  39  34  64  12  12  11  46  45  26  26  92  93  60  94  98 100  93\n",
      "  72  81  61  50  90  27  30  31  55  72  34  20  13  20  81  54  97  93\n",
      "  78  98  87  96  82  96  99  25  29  57  26  16  62  17  17   7  49  13\n",
      "  40  67  52  71  96  73  90  83  89  81  80  99  84  84  95  62  45  27\n",
      "  52  60  92  97  71  54  35   5  31  14  22  77  52  18  98  87  97  97\n",
      " 100  87]\n"
     ]
    }
   ],
   "source": [
    "rt_scores = series_rt.values\n",
    "print(rt_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Age of Ultron (2015)                74\n",
      "Cinderella (2015)                             85\n",
      "Ant-Man (2015)                                80\n",
      "Do You Believe? (2015)                        18\n",
      "Hot Tub Time Machine 2 (2015)                 14\n",
      "                                            ... \n",
      "Mr. Holmes (2015)                             87\n",
      "'71 (2015)                                    97\n",
      "Two Days, One Night (2014)                    97\n",
      "Gett: The Trial of Viviane Amsalem (2015)    100\n",
      "Kumiko, The Treasure Hunter (2015)            87\n",
      "Length: 146, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "series_custom = Series(rt_scores,index=film_names)\n",
    "print(series_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Minions (2015)      54\n",
       "Leviathan (2014)    99\n",
       "dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_custom[['Minions (2015)','Leviathan (2014)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Water Diviner (2015)        63\n",
      "Irrational Man (2015)           42\n",
      "Top Five (2014)                 86\n",
      "Shaun the Sheep Movie (2015)    99\n",
      "Love & Mercy (2015)             89\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fiveten = series_custom[5:10]\n",
    "print(fiveten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Avengers: Age of Ultron (2015)', 'Cinderella (2015)', 'Ant-Man (2015)', 'Do You Believe? (2015)', 'Hot Tub Time Machine 2 (2015)', 'The Water Diviner (2015)', 'Irrational Man (2015)', 'Top Five (2014)', 'Shaun the Sheep Movie (2015)', 'Love & Mercy (2015)', 'Far From The Madding Crowd (2015)', 'Black Sea (2015)', 'Leviathan (2014)', 'Unbroken (2014)', 'The Imitation Game (2014)', 'Taken 3 (2015)', 'Ted 2 (2015)', 'Southpaw (2015)', 'Night at the Museum: Secret of the Tomb (2014)', 'Pixels (2015)', 'McFarland, USA (2015)', 'Insidious: Chapter 3 (2015)', 'The Man From U.N.C.L.E. (2015)', 'Run All Night (2015)', 'Trainwreck (2015)', 'Selma (2014)', 'Ex Machina (2015)', 'Still Alice (2015)', 'Wild Tales (2014)', 'The End of the Tour (2015)', 'Red Army (2015)', 'When Marnie Was There (2015)', 'The Hunting Ground (2015)', 'The Boy Next Door (2015)', 'Aloha (2015)', 'The Loft (2015)', '5 Flights Up (2015)', 'Welcome to Me (2015)', 'Saint Laurent (2015)', 'Maps to the Stars (2015)', \"I'll See You In My Dreams (2015)\", 'Timbuktu (2015)', 'About Elly (2015)', 'The Diary of a Teenage Girl (2015)', 'Kingsman: The Secret Service (2015)', 'Tomorrowland (2015)', 'The Divergent Series: Insurgent (2015)', 'Annie (2014)', 'Fantastic Four (2015)', 'Terminator Genisys (2015)', 'Pitch Perfect 2 (2015)', 'Entourage (2015)', 'The Age of Adaline (2015)', 'Hot Pursuit (2015)', 'The DUFF (2015)', 'Black or White (2015)', 'Project Almanac (2015)', 'Ricki and the Flash (2015)', 'Seventh Son (2015)', 'Mortdecai (2015)', 'Unfinished Business (2015)', 'American Ultra (2015)', 'True Story (2015)', 'Child 44 (2015)', 'Dark Places (2015)', 'Birdman (2014)', 'The Gift (2015)', 'Unfriended (2015)', 'Monkey Kingdom (2015)', 'Mr. Turner (2014)', 'Seymour: An Introduction (2015)', 'The Wrecking Crew (2015)', 'American Sniper (2015)', 'Furious 7 (2015)', 'The Hobbit: The Battle of the Five Armies (2014)', 'San Andreas (2015)', 'Straight Outta Compton (2015)', 'Vacation (2015)', 'Chappie (2015)', 'Poltergeist (2015)', 'Paper Towns (2015)', 'Big Eyes (2014)', 'Blackhat (2015)', 'Self/less (2015)', 'Sinister 2 (2015)', 'Little Boy (2015)', 'Me and Earl and The Dying Girl (2015)', 'Maggie (2015)', 'Mad Max: Fury Road (2015)', 'Spy (2015)', 'The SpongeBob Movie: Sponge Out of Water (2015)', 'Paddington (2015)', 'Dope (2015)', 'What We Do in the Shadows (2015)', 'The Overnight (2015)', 'The Salt of the Earth (2015)', 'Song of the Sea (2014)', 'Fifty Shades of Grey (2015)', 'Get Hard (2015)', 'Focus (2015)', 'Jupiter Ascending (2015)', 'The Gallows (2015)', 'The Second Best Exotic Marigold Hotel (2015)', 'Strange Magic (2015)', 'The Gunman (2015)', 'Hitman: Agent 47 (2015)', 'Cake (2015)', 'The Vatican Tapes (2015)', 'A Little Chaos (2015)', 'The 100-Year-Old Man Who Climbed Out the Window and Disappeared (2015)', 'Escobar: Paradise Lost (2015)', 'Into the Woods (2014)', 'It Follows (2015)', 'Inherent Vice (2014)', 'A Most Violent Year (2014)', \"While We're Young (2015)\", 'Clouds of Sils Maria (2015)', 'Testament of Youth (2015)', 'Infinitely Polar Bear (2015)', 'Phoenix (2015)', 'The Wolfpack (2015)', 'The Stanford Prison Experiment (2015)', 'Tangerine (2015)', 'Magic Mike XXL (2015)', 'Home (2015)', 'The Wedding Ringer (2015)', 'Woman in Gold (2015)', 'The Last Five Years (2015)', 'Mission: Impossible â€“ Rogue Nation (2015)', 'Amy (2015)', 'Jurassic World (2015)', 'Minions (2015)', 'Max (2015)', 'Paul Blart: Mall Cop 2 (2015)', 'The Longest Ride (2015)', 'The Lazarus Effect (2015)', 'The Woman In Black 2 Angel of Death (2015)', 'Danny Collins (2015)', 'Spare Parts (2015)', 'Serena (2015)', 'Inside Out (2015)', 'Mr. Holmes (2015)', \"'71 (2015)\", 'Two Days, One Night (2014)', 'Gett: The Trial of Viviane Amsalem (2015)', 'Kumiko, The Treasure Hunter (2015)']\n"
     ]
    }
   ],
   "source": [
    "original_index=series_custom.index.tolist()\n",
    "print(original_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'71 (2015)\", '5 Flights Up (2015)', 'A Little Chaos (2015)', 'A Most Violent Year (2014)', 'About Elly (2015)', 'Aloha (2015)', 'American Sniper (2015)', 'American Ultra (2015)', 'Amy (2015)', 'Annie (2014)', 'Ant-Man (2015)', 'Avengers: Age of Ultron (2015)', 'Big Eyes (2014)', 'Birdman (2014)', 'Black Sea (2015)', 'Black or White (2015)', 'Blackhat (2015)', 'Cake (2015)', 'Chappie (2015)', 'Child 44 (2015)', 'Cinderella (2015)', 'Clouds of Sils Maria (2015)', 'Danny Collins (2015)', 'Dark Places (2015)', 'Do You Believe? (2015)', 'Dope (2015)', 'Entourage (2015)', 'Escobar: Paradise Lost (2015)', 'Ex Machina (2015)', 'Fantastic Four (2015)', 'Far From The Madding Crowd (2015)', 'Fifty Shades of Grey (2015)', 'Focus (2015)', 'Furious 7 (2015)', 'Get Hard (2015)', 'Gett: The Trial of Viviane Amsalem (2015)', 'Hitman: Agent 47 (2015)', 'Home (2015)', 'Hot Pursuit (2015)', 'Hot Tub Time Machine 2 (2015)', \"I'll See You In My Dreams (2015)\", 'Infinitely Polar Bear (2015)', 'Inherent Vice (2014)', 'Inside Out (2015)', 'Insidious: Chapter 3 (2015)', 'Into the Woods (2014)', 'Irrational Man (2015)', 'It Follows (2015)', 'Jupiter Ascending (2015)', 'Jurassic World (2015)', 'Kingsman: The Secret Service (2015)', 'Kumiko, The Treasure Hunter (2015)', 'Leviathan (2014)', 'Little Boy (2015)', 'Love & Mercy (2015)', 'Mad Max: Fury Road (2015)', 'Maggie (2015)', 'Magic Mike XXL (2015)', 'Maps to the Stars (2015)', 'Max (2015)', 'McFarland, USA (2015)', 'Me and Earl and The Dying Girl (2015)', 'Minions (2015)', 'Mission: Impossible â€“ Rogue Nation (2015)', 'Monkey Kingdom (2015)', 'Mortdecai (2015)', 'Mr. Holmes (2015)', 'Mr. Turner (2014)', 'Night at the Museum: Secret of the Tomb (2014)', 'Paddington (2015)', 'Paper Towns (2015)', 'Paul Blart: Mall Cop 2 (2015)', 'Phoenix (2015)', 'Pitch Perfect 2 (2015)', 'Pixels (2015)', 'Poltergeist (2015)', 'Project Almanac (2015)', 'Red Army (2015)', 'Ricki and the Flash (2015)', 'Run All Night (2015)', 'Saint Laurent (2015)', 'San Andreas (2015)', 'Self/less (2015)', 'Selma (2014)', 'Serena (2015)', 'Seventh Son (2015)', 'Seymour: An Introduction (2015)', 'Shaun the Sheep Movie (2015)', 'Sinister 2 (2015)', 'Song of the Sea (2014)', 'Southpaw (2015)', 'Spare Parts (2015)', 'Spy (2015)', 'Still Alice (2015)', 'Straight Outta Compton (2015)', 'Strange Magic (2015)', 'Taken 3 (2015)', 'Tangerine (2015)', 'Ted 2 (2015)', 'Terminator Genisys (2015)', 'Testament of Youth (2015)', 'The 100-Year-Old Man Who Climbed Out the Window and Disappeared (2015)', 'The Age of Adaline (2015)', 'The Boy Next Door (2015)', 'The DUFF (2015)', 'The Diary of a Teenage Girl (2015)', 'The Divergent Series: Insurgent (2015)', 'The End of the Tour (2015)', 'The Gallows (2015)', 'The Gift (2015)', 'The Gunman (2015)', 'The Hobbit: The Battle of the Five Armies (2014)', 'The Hunting Ground (2015)', 'The Imitation Game (2014)', 'The Last Five Years (2015)', 'The Lazarus Effect (2015)', 'The Loft (2015)', 'The Longest Ride (2015)', 'The Man From U.N.C.L.E. (2015)', 'The Overnight (2015)', 'The Salt of the Earth (2015)', 'The Second Best Exotic Marigold Hotel (2015)', 'The SpongeBob Movie: Sponge Out of Water (2015)', 'The Stanford Prison Experiment (2015)', 'The Vatican Tapes (2015)', 'The Water Diviner (2015)', 'The Wedding Ringer (2015)', 'The Wolfpack (2015)', 'The Woman In Black 2 Angel of Death (2015)', 'The Wrecking Crew (2015)', 'Timbuktu (2015)', 'Tomorrowland (2015)', 'Top Five (2014)', 'Trainwreck (2015)', 'True Story (2015)', 'Two Days, One Night (2014)', 'Unbroken (2014)', 'Unfinished Business (2015)', 'Unfriended (2015)', 'Vacation (2015)', 'Welcome to Me (2015)', 'What We Do in the Shadows (2015)', 'When Marnie Was There (2015)', \"While We're Young (2015)\", 'Wild Tales (2014)', 'Woman in Gold (2015)']\n",
      "'71 (2015)                          97\n",
      "5 Flights Up (2015)                 52\n",
      "A Little Chaos (2015)               40\n",
      "A Most Violent Year (2014)          90\n",
      "About Elly (2015)                   97\n",
      "                                    ..\n",
      "What We Do in the Shadows (2015)    96\n",
      "When Marnie Was There (2015)        89\n",
      "While We're Young (2015)            83\n",
      "Wild Tales (2014)                   96\n",
      "Woman in Gold (2015)                52\n",
      "Length: 146, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sorted_index=sorted(original_index)\n",
    "print(sorted_index)\n",
    "sorted_by_index=series_custom.reindex(sorted_index)#和ndarray中的resetindex一样\n",
    "print(sorted_by_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#两个series进行想加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Age of Ultron (2015)                74\n",
      "Cinderella (2015)                             85\n",
      "Ant-Man (2015)                                80\n",
      "Do You Believe? (2015)                        18\n",
      "Hot Tub Time Machine 2 (2015)                 14\n",
      "                                            ... \n",
      "Mr. Holmes (2015)                             87\n",
      "'71 (2015)                                    97\n",
      "Two Days, One Night (2014)                    97\n",
      "Gett: The Trial of Viviane Amsalem (2015)    100\n",
      "Kumiko, The Treasure Hunter (2015)            87\n",
      "Length: 146, dtype: int64\n",
      "------------\n",
      "Avengers: Age of Ultron (2015)               148\n",
      "Cinderella (2015)                            170\n",
      "Ant-Man (2015)                               160\n",
      "Do You Believe? (2015)                        36\n",
      "Hot Tub Time Machine 2 (2015)                 28\n",
      "                                            ... \n",
      "Mr. Holmes (2015)                            174\n",
      "'71 (2015)                                   194\n",
      "Two Days, One Night (2014)                   194\n",
      "Gett: The Trial of Viviane Amsalem (2015)    200\n",
      "Kumiko, The Treasure Hunter (2015)           174\n",
      "Length: 146, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(series_custom)\n",
    "print('------------')\n",
    "print(np.add(series_custom,series_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply sin function to each value,最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sin(series_custom)\n",
    "np.max(series_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查询大于50的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Age of Ultron (2015)                74\n",
      "Cinderella (2015)                             85\n",
      "Ant-Man (2015)                                80\n",
      "The Water Diviner (2015)                      63\n",
      "Top Five (2014)                               86\n",
      "                                            ... \n",
      "Mr. Holmes (2015)                             87\n",
      "'71 (2015)                                    97\n",
      "Two Days, One Night (2014)                    97\n",
      "Gett: The Trial of Viviane Amsalem (2015)    100\n",
      "Kumiko, The Treasure Hunter (2015)            87\n",
      "Length: 94, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "series_custom>50\n",
    "series_greater_than_50 = series_custom[series_custom>50]\n",
    "print(series_greater_than_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Age of Ultron (2015)                                            74\n",
      "The Water Diviner (2015)                                                  63\n",
      "Unbroken (2014)                                                           51\n",
      "Southpaw (2015)                                                           59\n",
      "Insidious: Chapter 3 (2015)                                               59\n",
      "The Man From U.N.C.L.E. (2015)                                            68\n",
      "Run All Night (2015)                                                      60\n",
      "5 Flights Up (2015)                                                       52\n",
      "Welcome to Me (2015)                                                      71\n",
      "Saint Laurent (2015)                                                      51\n",
      "Maps to the Stars (2015)                                                  60\n",
      "Pitch Perfect 2 (2015)                                                    67\n",
      "The Age of Adaline (2015)                                                 54\n",
      "The DUFF (2015)                                                           71\n",
      "Ricki and the Flash (2015)                                                64\n",
      "Unfriended (2015)                                                         60\n",
      "American Sniper (2015)                                                    72\n",
      "The Hobbit: The Battle of the Five Armies (2014)                          61\n",
      "Paper Towns (2015)                                                        55\n",
      "Big Eyes (2014)                                                           72\n",
      "Maggie (2015)                                                             54\n",
      "Focus (2015)                                                              57\n",
      "The Second Best Exotic Marigold Hotel (2015)                              62\n",
      "The 100-Year-Old Man Who Climbed Out the Window and Disappeared (2015)    67\n",
      "Escobar: Paradise Lost (2015)                                             52\n",
      "Into the Woods (2014)                                                     71\n",
      "Inherent Vice (2014)                                                      73\n",
      "Magic Mike XXL (2015)                                                     62\n",
      "Woman in Gold (2015)                                                      52\n",
      "The Last Five Years (2015)                                                60\n",
      "Jurassic World (2015)                                                     71\n",
      "Minions (2015)                                                            54\n",
      "Spare Parts (2015)                                                        52\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "criteria_one = series_custom>50\n",
    "criteria_two = series_custom<75\n",
    "both_criteria = series_custom[criteria_one&criteria_two]\n",
    "print(both_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算两个不同媒体的评分平均值根据index=film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILM\n",
      "Avengers: Age of Ultron (2015)               80.0\n",
      "Cinderella (2015)                            82.5\n",
      "Ant-Man (2015)                               85.0\n",
      "Do You Believe? (2015)                       51.0\n",
      "Hot Tub Time Machine 2 (2015)                21.0\n",
      "                                             ... \n",
      "Mr. Holmes (2015)                            82.5\n",
      "'71 (2015)                                   89.5\n",
      "Two Days, One Night (2014)                   87.5\n",
      "Gett: The Trial of Viviane Amsalem (2015)    90.5\n",
      "Kumiko, The Treasure Hunter (2015)           75.0\n",
      "Length: 146, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rt_critics=Series(fandango['RottenTomatoes'].values,index=fandango['FILM'])\n",
    "rt_users =Series(fandango['RottenTomatoes_User'].values,index=fandango['FILM'])\n",
    "rt_mean = (rt_critics + rt_users)/2\n",
    "\n",
    "print(rt_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop that column from the DataFrame,without the FILM column dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(146, 22)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fandango = pd.read_csv('fandango_score_comparison.csv')\n",
    "print(type(fandango))\n",
    "print(fandango.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Avengers: Age of Ultron (2015)', 'Cinderella (2015)', 'Ant-Man (2015)',\n",
      "       'Do You Believe? (2015)', 'Hot Tub Time Machine 2 (2015)',\n",
      "       'The Water Diviner (2015)', 'Irrational Man (2015)', 'Top Five (2014)',\n",
      "       'Shaun the Sheep Movie (2015)', 'Love & Mercy (2015)',\n",
      "       ...\n",
      "       'The Woman In Black 2 Angel of Death (2015)', 'Danny Collins (2015)',\n",
      "       'Spare Parts (2015)', 'Serena (2015)', 'Inside Out (2015)',\n",
      "       'Mr. Holmes (2015)', ''71 (2015)', 'Two Days, One Night (2014)',\n",
      "       'Gett: The Trial of Viviane Amsalem (2015)',\n",
      "       'Kumiko, The Treasure Hunter (2015)'],\n",
      "      dtype='object', name='FILM', length=146)\n",
      "(146, 22)\n"
     ]
    }
   ],
   "source": [
    "fandango_films=fandango.set_index('FILM',drop=False)\n",
    "print(fandango_films.index)\n",
    "print(fandango_films.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#两个string值之间：，表示按照abcdedg..这样的排序进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FILM                          Kumiko, The Treasure Hunter (2015)\n",
       "RottenTomatoes                                                87\n",
       "RottenTomatoes_User                                           63\n",
       "Metacritic                                                    68\n",
       "Metacritic_User                                              6.4\n",
       "IMDB                                                         6.7\n",
       "Fandango_Stars                                               3.5\n",
       "Fandango_Ratingvalue                                         3.5\n",
       "RT_norm                                                     4.35\n",
       "RT_user_norm                                                3.15\n",
       "Metacritic_norm                                              3.4\n",
       "Metacritic_user_nom                                          3.2\n",
       "IMDB_norm                                                   3.35\n",
       "RT_norm_round                                                4.5\n",
       "RT_user_norm_round                                             3\n",
       "Metacritic_norm_round                                        3.5\n",
       "Metacritic_user_norm_round                                     3\n",
       "IMDB_norm_round                                              3.5\n",
       "Metacritic_user_vote_count                                    19\n",
       "IMDB_user_vote_count                                        5289\n",
       "Fandango_votes                                                41\n",
       "Fandango_Difference                                            0\n",
       "Name: Kumiko, The Treasure Hunter (2015), dtype: object"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fandango_films[\"Avengers: Age of Ultron (2015)\":\"Hot Tub Time Machine 2 (2015)\"]\n",
    "fandango_films.loc[\"Avengers: Age of Ultron (2015)\":\"Hot Tub Time Machine 2 (2015)\"]\n",
    "fandango_films.loc['Kumiko, The Treasure Hunter (2015)']#查询某一具体的电影\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILM</th>\n",
       "      <th>RottenTomatoes</th>\n",
       "      <th>RottenTomatoes_User</th>\n",
       "      <th>Metacritic</th>\n",
       "      <th>Metacritic_User</th>\n",
       "      <th>IMDB</th>\n",
       "      <th>Fandango_Stars</th>\n",
       "      <th>Fandango_Ratingvalue</th>\n",
       "      <th>RT_norm</th>\n",
       "      <th>RT_user_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>IMDB_norm</th>\n",
       "      <th>RT_norm_round</th>\n",
       "      <th>RT_user_norm_round</th>\n",
       "      <th>Metacritic_norm_round</th>\n",
       "      <th>Metacritic_user_norm_round</th>\n",
       "      <th>IMDB_norm_round</th>\n",
       "      <th>Metacritic_user_vote_count</th>\n",
       "      <th>IMDB_user_vote_count</th>\n",
       "      <th>Fandango_votes</th>\n",
       "      <th>Fandango_Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FILM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kumiko, The Treasure Hunter (2015)</th>\n",
       "      <td>Kumiko, The Treasure Hunter (2015)</td>\n",
       "      <td>87</td>\n",
       "      <td>63</td>\n",
       "      <td>68</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>3.35</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>19</td>\n",
       "      <td>5289</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do You Believe? (2015)</th>\n",
       "      <td>Do You Believe? (2015)</td>\n",
       "      <td>18</td>\n",
       "      <td>84</td>\n",
       "      <td>22</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>31</td>\n",
       "      <td>3136</td>\n",
       "      <td>1793</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ant-Man (2015)</th>\n",
       "      <td>Ant-Man (2015)</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>64</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>627</td>\n",
       "      <td>103660</td>\n",
       "      <td>12055</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  FILM  \\\n",
       "FILM                                                                     \n",
       "Kumiko, The Treasure Hunter (2015)  Kumiko, The Treasure Hunter (2015)   \n",
       "Do You Believe? (2015)                          Do You Believe? (2015)   \n",
       "Ant-Man (2015)                                          Ant-Man (2015)   \n",
       "\n",
       "                                    RottenTomatoes  RottenTomatoes_User  \\\n",
       "FILM                                                                      \n",
       "Kumiko, The Treasure Hunter (2015)              87                   63   \n",
       "Do You Believe? (2015)                          18                   84   \n",
       "Ant-Man (2015)                                  80                   90   \n",
       "\n",
       "                                    Metacritic  Metacritic_User  IMDB  \\\n",
       "FILM                                                                    \n",
       "Kumiko, The Treasure Hunter (2015)          68              6.4   6.7   \n",
       "Do You Believe? (2015)                      22              4.7   5.4   \n",
       "Ant-Man (2015)                              64              8.1   7.8   \n",
       "\n",
       "                                    Fandango_Stars  Fandango_Ratingvalue  \\\n",
       "FILM                                                                       \n",
       "Kumiko, The Treasure Hunter (2015)             3.5                   3.5   \n",
       "Do You Believe? (2015)                         5.0                   4.5   \n",
       "Ant-Man (2015)                                 5.0                   4.5   \n",
       "\n",
       "                                    RT_norm  RT_user_norm  ...  IMDB_norm  \\\n",
       "FILM                                                       ...              \n",
       "Kumiko, The Treasure Hunter (2015)     4.35          3.15  ...       3.35   \n",
       "Do You Believe? (2015)                 0.90          4.20  ...       2.70   \n",
       "Ant-Man (2015)                         4.00          4.50  ...       3.90   \n",
       "\n",
       "                                    RT_norm_round  RT_user_norm_round  \\\n",
       "FILM                                                                    \n",
       "Kumiko, The Treasure Hunter (2015)            4.5                 3.0   \n",
       "Do You Believe? (2015)                        1.0                 4.0   \n",
       "Ant-Man (2015)                                4.0                 4.5   \n",
       "\n",
       "                                    Metacritic_norm_round  \\\n",
       "FILM                                                        \n",
       "Kumiko, The Treasure Hunter (2015)                    3.5   \n",
       "Do You Believe? (2015)                                1.0   \n",
       "Ant-Man (2015)                                        3.0   \n",
       "\n",
       "                                    Metacritic_user_norm_round  \\\n",
       "FILM                                                             \n",
       "Kumiko, The Treasure Hunter (2015)                         3.0   \n",
       "Do You Believe? (2015)                                     2.5   \n",
       "Ant-Man (2015)                                             4.0   \n",
       "\n",
       "                                    IMDB_norm_round  \\\n",
       "FILM                                                  \n",
       "Kumiko, The Treasure Hunter (2015)              3.5   \n",
       "Do You Believe? (2015)                          2.5   \n",
       "Ant-Man (2015)                                  4.0   \n",
       "\n",
       "                                    Metacritic_user_vote_count  \\\n",
       "FILM                                                             \n",
       "Kumiko, The Treasure Hunter (2015)                          19   \n",
       "Do You Believe? (2015)                                      31   \n",
       "Ant-Man (2015)                                             627   \n",
       "\n",
       "                                    IMDB_user_vote_count  Fandango_votes  \\\n",
       "FILM                                                                       \n",
       "Kumiko, The Treasure Hunter (2015)                  5289              41   \n",
       "Do You Believe? (2015)                              3136            1793   \n",
       "Ant-Man (2015)                                    103660           12055   \n",
       "\n",
       "                                    Fandango_Difference  \n",
       "FILM                                                     \n",
       "Kumiko, The Treasure Hunter (2015)                  0.0  \n",
       "Do You Believe? (2015)                              0.5  \n",
       "Ant-Man (2015)                                      0.5  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = ['Kumiko, The Treasure Hunter (2015)','Do You Believe? (2015)','Ant-Man (2015)']\n",
    "fandango_films.loc[movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILM                           object\n",
      "RottenTomatoes                  int64\n",
      "RottenTomatoes_User             int64\n",
      "Metacritic                      int64\n",
      "Metacritic_User               float64\n",
      "IMDB                          float64\n",
      "Fandango_Stars                float64\n",
      "Fandango_Ratingvalue          float64\n",
      "RT_norm                       float64\n",
      "RT_user_norm                  float64\n",
      "Metacritic_norm               float64\n",
      "Metacritic_user_nom           float64\n",
      "IMDB_norm                     float64\n",
      "RT_norm_round                 float64\n",
      "RT_user_norm_round            float64\n",
      "Metacritic_norm_round         float64\n",
      "Metacritic_user_norm_round    float64\n",
      "IMDB_norm_round               float64\n",
      "Metacritic_user_vote_count      int64\n",
      "IMDB_user_vote_count            int64\n",
      "Fandango_votes                  int64\n",
      "Fandango_Difference           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "types = fandango_films.dtypes\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#过滤数据类型只要float类型\n",
    "float_columns = types[types.values =='float64'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Metacritic_User  IMDB  \\\n",
      "FILM                                                               \n",
      "Avengers: Age of Ultron (2015)                         7.1   7.8   \n",
      "Cinderella (2015)                                      7.5   7.1   \n",
      "Ant-Man (2015)                                         8.1   7.8   \n",
      "Do You Believe? (2015)                                 4.7   5.4   \n",
      "Hot Tub Time Machine 2 (2015)                          3.4   5.1   \n",
      "...                                                    ...   ...   \n",
      "Mr. Holmes (2015)                                      7.9   7.4   \n",
      "'71 (2015)                                             7.5   7.2   \n",
      "Two Days, One Night (2014)                             8.8   7.4   \n",
      "Gett: The Trial of Viviane Amsalem (2015)              7.3   7.8   \n",
      "Kumiko, The Treasure Hunter (2015)                     6.4   6.7   \n",
      "\n",
      "                                           Fandango_Stars  \\\n",
      "FILM                                                        \n",
      "Avengers: Age of Ultron (2015)                        5.0   \n",
      "Cinderella (2015)                                     5.0   \n",
      "Ant-Man (2015)                                        5.0   \n",
      "Do You Believe? (2015)                                5.0   \n",
      "Hot Tub Time Machine 2 (2015)                         3.5   \n",
      "...                                                   ...   \n",
      "Mr. Holmes (2015)                                     4.0   \n",
      "'71 (2015)                                            3.5   \n",
      "Two Days, One Night (2014)                            3.5   \n",
      "Gett: The Trial of Viviane Amsalem (2015)             3.5   \n",
      "Kumiko, The Treasure Hunter (2015)                    3.5   \n",
      "\n",
      "                                           Fandango_Ratingvalue  RT_norm  \\\n",
      "FILM                                                                       \n",
      "Avengers: Age of Ultron (2015)                              4.5     3.70   \n",
      "Cinderella (2015)                                           4.5     4.25   \n",
      "Ant-Man (2015)                                              4.5     4.00   \n",
      "Do You Believe? (2015)                                      4.5     0.90   \n",
      "Hot Tub Time Machine 2 (2015)                               3.0     0.70   \n",
      "...                                                         ...      ...   \n",
      "Mr. Holmes (2015)                                           4.0     4.35   \n",
      "'71 (2015)                                                  3.5     4.85   \n",
      "Two Days, One Night (2014)                                  3.5     4.85   \n",
      "Gett: The Trial of Viviane Amsalem (2015)                   3.5     5.00   \n",
      "Kumiko, The Treasure Hunter (2015)                          3.5     4.35   \n",
      "\n",
      "                                           RT_user_norm  Metacritic_norm  \\\n",
      "FILM                                                                       \n",
      "Avengers: Age of Ultron (2015)                     4.30             3.30   \n",
      "Cinderella (2015)                                  4.00             3.35   \n",
      "Ant-Man (2015)                                     4.50             3.20   \n",
      "Do You Believe? (2015)                             4.20             1.10   \n",
      "Hot Tub Time Machine 2 (2015)                      1.40             1.45   \n",
      "...                                                 ...              ...   \n",
      "Mr. Holmes (2015)                                  3.90             3.35   \n",
      "'71 (2015)                                         4.10             4.15   \n",
      "Two Days, One Night (2014)                         3.90             4.45   \n",
      "Gett: The Trial of Viviane Amsalem (2015)          4.05             4.50   \n",
      "Kumiko, The Treasure Hunter (2015)                 3.15             3.40   \n",
      "\n",
      "                                           Metacritic_user_nom  IMDB_norm  \\\n",
      "FILM                                                                        \n",
      "Avengers: Age of Ultron (2015)                            3.55       3.90   \n",
      "Cinderella (2015)                                         3.75       3.55   \n",
      "Ant-Man (2015)                                            4.05       3.90   \n",
      "Do You Believe? (2015)                                    2.35       2.70   \n",
      "Hot Tub Time Machine 2 (2015)                             1.70       2.55   \n",
      "...                                                        ...        ...   \n",
      "Mr. Holmes (2015)                                         3.95       3.70   \n",
      "'71 (2015)                                                3.75       3.60   \n",
      "Two Days, One Night (2014)                                4.40       3.70   \n",
      "Gett: The Trial of Viviane Amsalem (2015)                 3.65       3.90   \n",
      "Kumiko, The Treasure Hunter (2015)                        3.20       3.35   \n",
      "\n",
      "                                           RT_norm_round  RT_user_norm_round  \\\n",
      "FILM                                                                           \n",
      "Avengers: Age of Ultron (2015)                       3.5                 4.5   \n",
      "Cinderella (2015)                                    4.5                 4.0   \n",
      "Ant-Man (2015)                                       4.0                 4.5   \n",
      "Do You Believe? (2015)                               1.0                 4.0   \n",
      "Hot Tub Time Machine 2 (2015)                        0.5                 1.5   \n",
      "...                                                  ...                 ...   \n",
      "Mr. Holmes (2015)                                    4.5                 4.0   \n",
      "'71 (2015)                                           5.0                 4.0   \n",
      "Two Days, One Night (2014)                           5.0                 4.0   \n",
      "Gett: The Trial of Viviane Amsalem (2015)            5.0                 4.0   \n",
      "Kumiko, The Treasure Hunter (2015)                   4.5                 3.0   \n",
      "\n",
      "                                           Metacritic_norm_round  \\\n",
      "FILM                                                               \n",
      "Avengers: Age of Ultron (2015)                               3.5   \n",
      "Cinderella (2015)                                            3.5   \n",
      "Ant-Man (2015)                                               3.0   \n",
      "Do You Believe? (2015)                                       1.0   \n",
      "Hot Tub Time Machine 2 (2015)                                1.5   \n",
      "...                                                          ...   \n",
      "Mr. Holmes (2015)                                            3.5   \n",
      "'71 (2015)                                                   4.0   \n",
      "Two Days, One Night (2014)                                   4.5   \n",
      "Gett: The Trial of Viviane Amsalem (2015)                    4.5   \n",
      "Kumiko, The Treasure Hunter (2015)                           3.5   \n",
      "\n",
      "                                           Metacritic_user_norm_round  \\\n",
      "FILM                                                                    \n",
      "Avengers: Age of Ultron (2015)                                    3.5   \n",
      "Cinderella (2015)                                                 4.0   \n",
      "Ant-Man (2015)                                                    4.0   \n",
      "Do You Believe? (2015)                                            2.5   \n",
      "Hot Tub Time Machine 2 (2015)                                     1.5   \n",
      "...                                                               ...   \n",
      "Mr. Holmes (2015)                                                 4.0   \n",
      "'71 (2015)                                                        4.0   \n",
      "Two Days, One Night (2014)                                        4.5   \n",
      "Gett: The Trial of Viviane Amsalem (2015)                         3.5   \n",
      "Kumiko, The Treasure Hunter (2015)                                3.0   \n",
      "\n",
      "                                           IMDB_norm_round  \\\n",
      "FILM                                                         \n",
      "Avengers: Age of Ultron (2015)                         4.0   \n",
      "Cinderella (2015)                                      3.5   \n",
      "Ant-Man (2015)                                         4.0   \n",
      "Do You Believe? (2015)                                 2.5   \n",
      "Hot Tub Time Machine 2 (2015)                          2.5   \n",
      "...                                                    ...   \n",
      "Mr. Holmes (2015)                                      3.5   \n",
      "'71 (2015)                                             3.5   \n",
      "Two Days, One Night (2014)                             3.5   \n",
      "Gett: The Trial of Viviane Amsalem (2015)              4.0   \n",
      "Kumiko, The Treasure Hunter (2015)                     3.5   \n",
      "\n",
      "                                           Fandango_Difference  \n",
      "FILM                                                            \n",
      "Avengers: Age of Ultron (2015)                             0.5  \n",
      "Cinderella (2015)                                          0.5  \n",
      "Ant-Man (2015)                                             0.5  \n",
      "Do You Believe? (2015)                                     0.5  \n",
      "Hot Tub Time Machine 2 (2015)                              0.5  \n",
      "...                                                        ...  \n",
      "Mr. Holmes (2015)                                          0.0  \n",
      "'71 (2015)                                                 0.0  \n",
      "Two Days, One Night (2014)                                 0.0  \n",
      "Gett: The Trial of Viviane Amsalem (2015)                  0.0  \n",
      "Kumiko, The Treasure Hunter (2015)                         0.0  \n",
      "\n",
      "[146 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "float_df = fandango_films[float_columns]\n",
    "print(float_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metacritic_User               1.505529\n",
      "IMDB                          0.955447\n",
      "Fandango_Stars                0.538532\n",
      "Fandango_Ratingvalue          0.501106\n",
      "RT_norm                       1.503265\n",
      "RT_user_norm                  0.997787\n",
      "Metacritic_norm               0.972522\n",
      "Metacritic_user_nom           0.752765\n",
      "IMDB_norm                     0.477723\n",
      "RT_norm_round                 1.509404\n",
      "RT_user_norm_round            1.003559\n",
      "Metacritic_norm_round         0.987561\n",
      "Metacritic_user_norm_round    0.785412\n",
      "IMDB_norm_round               0.501043\n",
      "Fandango_Difference           0.152141\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "deviations = float_df.apply(lambda x:np.std(x))\n",
    "print(deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda计算标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILM                           object\n",
      "RottenTomatoes                  int64\n",
      "RottenTomatoes_User             int64\n",
      "Metacritic                      int64\n",
      "Metacritic_User               float64\n",
      "IMDB                          float64\n",
      "Fandango_Stars                float64\n",
      "Fandango_Ratingvalue          float64\n",
      "RT_norm                       float64\n",
      "RT_user_norm                  float64\n",
      "Metacritic_norm               float64\n",
      "Metacritic_user_nom           float64\n",
      "IMDB_norm                     float64\n",
      "RT_norm_round                 float64\n",
      "RT_user_norm_round            float64\n",
      "Metacritic_norm_round         float64\n",
      "Metacritic_user_norm_round    float64\n",
      "IMDB_norm_round               float64\n",
      "Metacritic_user_vote_count      int64\n",
      "IMDB_user_vote_count            int64\n",
      "Fandango_votes                  int64\n",
      "Fandango_Difference           float64\n",
      "dtype: object\n",
      "                                           Metacritic_User  IMDB  \\\n",
      "FILM                                                               \n",
      "Avengers: Age of Ultron (2015)                         7.1   7.8   \n",
      "Cinderella (2015)                                      7.5   7.1   \n",
      "Ant-Man (2015)                                         8.1   7.8   \n",
      "Do You Believe? (2015)                                 4.7   5.4   \n",
      "Hot Tub Time Machine 2 (2015)                          3.4   5.1   \n",
      "...                                                    ...   ...   \n",
      "Mr. Holmes (2015)                                      7.9   7.4   \n",
      "'71 (2015)                                             7.5   7.2   \n",
      "Two Days, One Night (2014)                             8.8   7.4   \n",
      "Gett: The Trial of Viviane Amsalem (2015)              7.3   7.8   \n",
      "Kumiko, The Treasure Hunter (2015)                     6.4   6.7   \n",
      "\n",
      "                                           Fandango_Stars  \\\n",
      "FILM                                                        \n",
      "Avengers: Age of Ultron (2015)                        5.0   \n",
      "Cinderella (2015)                                     5.0   \n",
      "Ant-Man (2015)                                        5.0   \n",
      "Do You Believe? (2015)                                5.0   \n",
      "Hot Tub Time Machine 2 (2015)                         3.5   \n",
      "...                                                   ...   \n",
      "Mr. Holmes (2015)                                     4.0   \n",
      "'71 (2015)                                            3.5   \n",
      "Two Days, One Night (2014)                            3.5   \n",
      "Gett: The Trial of Viviane Amsalem (2015)             3.5   \n",
      "Kumiko, The Treasure Hunter (2015)                    3.5   \n",
      "\n",
      "                                           Fandango_Ratingvalue  RT_norm  \\\n",
      "FILM                                                                       \n",
      "Avengers: Age of Ultron (2015)                              4.5     3.70   \n",
      "Cinderella (2015)                                           4.5     4.25   \n",
      "Ant-Man (2015)                                              4.5     4.00   \n",
      "Do You Believe? (2015)                                      4.5     0.90   \n",
      "Hot Tub Time Machine 2 (2015)                               3.0     0.70   \n",
      "...                                                         ...      ...   \n",
      "Mr. Holmes (2015)                                           4.0     4.35   \n",
      "'71 (2015)                                                  3.5     4.85   \n",
      "Two Days, One Night (2014)                                  3.5     4.85   \n",
      "Gett: The Trial of Viviane Amsalem (2015)                   3.5     5.00   \n",
      "Kumiko, The Treasure Hunter (2015)                          3.5     4.35   \n",
      "\n",
      "                                           RT_user_norm  Metacritic_norm  \\\n",
      "FILM                                                                       \n",
      "Avengers: Age of Ultron (2015)                     4.30             3.30   \n",
      "Cinderella (2015)                                  4.00             3.35   \n",
      "Ant-Man (2015)                                     4.50             3.20   \n",
      "Do You Believe? (2015)                             4.20             1.10   \n",
      "Hot Tub Time Machine 2 (2015)                      1.40             1.45   \n",
      "...                                                 ...              ...   \n",
      "Mr. Holmes (2015)                                  3.90             3.35   \n",
      "'71 (2015)                                         4.10             4.15   \n",
      "Two Days, One Night (2014)                         3.90             4.45   \n",
      "Gett: The Trial of Viviane Amsalem (2015)          4.05             4.50   \n",
      "Kumiko, The Treasure Hunter (2015)                 3.15             3.40   \n",
      "\n",
      "                                           Metacritic_user_nom  IMDB_norm  \\\n",
      "FILM                                                                        \n",
      "Avengers: Age of Ultron (2015)                            3.55       3.90   \n",
      "Cinderella (2015)                                         3.75       3.55   \n",
      "Ant-Man (2015)                                            4.05       3.90   \n",
      "Do You Believe? (2015)                                    2.35       2.70   \n",
      "Hot Tub Time Machine 2 (2015)                             1.70       2.55   \n",
      "...                                                        ...        ...   \n",
      "Mr. Holmes (2015)                                         3.95       3.70   \n",
      "'71 (2015)                                                3.75       3.60   \n",
      "Two Days, One Night (2014)                                4.40       3.70   \n",
      "Gett: The Trial of Viviane Amsalem (2015)                 3.65       3.90   \n",
      "Kumiko, The Treasure Hunter (2015)                        3.20       3.35   \n",
      "\n",
      "                                           RT_norm_round  RT_user_norm_round  \\\n",
      "FILM                                                                           \n",
      "Avengers: Age of Ultron (2015)                       3.5                 4.5   \n",
      "Cinderella (2015)                                    4.5                 4.0   \n",
      "Ant-Man (2015)                                       4.0                 4.5   \n",
      "Do You Believe? (2015)                               1.0                 4.0   \n",
      "Hot Tub Time Machine 2 (2015)                        0.5                 1.5   \n",
      "...                                                  ...                 ...   \n",
      "Mr. Holmes (2015)                                    4.5                 4.0   \n",
      "'71 (2015)                                           5.0                 4.0   \n",
      "Two Days, One Night (2014)                           5.0                 4.0   \n",
      "Gett: The Trial of Viviane Amsalem (2015)            5.0                 4.0   \n",
      "Kumiko, The Treasure Hunter (2015)                   4.5                 3.0   \n",
      "\n",
      "                                           Metacritic_norm_round  \\\n",
      "FILM                                                               \n",
      "Avengers: Age of Ultron (2015)                               3.5   \n",
      "Cinderella (2015)                                            3.5   \n",
      "Ant-Man (2015)                                               3.0   \n",
      "Do You Believe? (2015)                                       1.0   \n",
      "Hot Tub Time Machine 2 (2015)                                1.5   \n",
      "...                                                          ...   \n",
      "Mr. Holmes (2015)                                            3.5   \n",
      "'71 (2015)                                                   4.0   \n",
      "Two Days, One Night (2014)                                   4.5   \n",
      "Gett: The Trial of Viviane Amsalem (2015)                    4.5   \n",
      "Kumiko, The Treasure Hunter (2015)                           3.5   \n",
      "\n",
      "                                           Metacritic_user_norm_round  \\\n",
      "FILM                                                                    \n",
      "Avengers: Age of Ultron (2015)                                    3.5   \n",
      "Cinderella (2015)                                                 4.0   \n",
      "Ant-Man (2015)                                                    4.0   \n",
      "Do You Believe? (2015)                                            2.5   \n",
      "Hot Tub Time Machine 2 (2015)                                     1.5   \n",
      "...                                                               ...   \n",
      "Mr. Holmes (2015)                                                 4.0   \n",
      "'71 (2015)                                                        4.0   \n",
      "Two Days, One Night (2014)                                        4.5   \n",
      "Gett: The Trial of Viviane Amsalem (2015)                         3.5   \n",
      "Kumiko, The Treasure Hunter (2015)                                3.0   \n",
      "\n",
      "                                           IMDB_norm_round  \\\n",
      "FILM                                                         \n",
      "Avengers: Age of Ultron (2015)                         4.0   \n",
      "Cinderella (2015)                                      3.5   \n",
      "Ant-Man (2015)                                         4.0   \n",
      "Do You Believe? (2015)                                 2.5   \n",
      "Hot Tub Time Machine 2 (2015)                          2.5   \n",
      "...                                                    ...   \n",
      "Mr. Holmes (2015)                                      3.5   \n",
      "'71 (2015)                                             3.5   \n",
      "Two Days, One Night (2014)                             3.5   \n",
      "Gett: The Trial of Viviane Amsalem (2015)              4.0   \n",
      "Kumiko, The Treasure Hunter (2015)                     3.5   \n",
      "\n",
      "                                           Fandango_Difference  \n",
      "FILM                                                            \n",
      "Avengers: Age of Ultron (2015)                             0.5  \n",
      "Cinderella (2015)                                          0.5  \n",
      "Ant-Man (2015)                                             0.5  \n",
      "Do You Believe? (2015)                                     0.5  \n",
      "Hot Tub Time Machine 2 (2015)                              0.5  \n",
      "...                                                        ...  \n",
      "Mr. Holmes (2015)                                          0.0  \n",
      "'71 (2015)                                                 0.0  \n",
      "Two Days, One Night (2014)                                 0.0  \n",
      "Gett: The Trial of Viviane Amsalem (2015)                  0.0  \n",
      "Kumiko, The Treasure Hunter (2015)                         0.0  \n",
      "\n",
      "[146 rows x 15 columns]\n",
      "Metacritic_User               1.505529\n",
      "IMDB                          0.955447\n",
      "Fandango_Stars                0.538532\n",
      "Fandango_Ratingvalue          0.501106\n",
      "RT_norm                       1.503265\n",
      "RT_user_norm                  0.997787\n",
      "Metacritic_norm               0.972522\n",
      "Metacritic_user_nom           0.752765\n",
      "IMDB_norm                     0.477723\n",
      "RT_norm_round                 1.509404\n",
      "RT_user_norm_round            1.003559\n",
      "Metacritic_norm_round         0.987561\n",
      "Metacritic_user_norm_round    0.785412\n",
      "IMDB_norm_round               0.501043\n",
      "Fandango_Difference           0.152141\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "types = fandango_films.dtypes\n",
    "print(types)\n",
    "float_columns = types[types.values == 'float64'].index\n",
    "float_df = fandango_films[float_columns]\n",
    "print(float_df)\n",
    "deviations = float_df.apply(lambda x:np.std(x))\n",
    "print(deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取两列，对这两个列做标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FILM\n",
       "Avengers: Age of Ultron (2015)               0.375\n",
       "Cinderella (2015)                            0.125\n",
       "Ant-Man (2015)                               0.225\n",
       "Do You Believe? (2015)                       0.925\n",
       "Hot Tub Time Machine 2 (2015)                0.150\n",
       "                                             ...  \n",
       "Mr. Holmes (2015)                            0.025\n",
       "'71 (2015)                                   0.175\n",
       "Two Days, One Night (2014)                   0.250\n",
       "Gett: The Trial of Viviane Amsalem (2015)    0.200\n",
       "Kumiko, The Treasure Hunter (2015)           0.025\n",
       "Length: 146, dtype: float64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_mt_user = float_df[['RT_user_norm','Metacritic_user_nom']]\n",
    "rt_mt_user.apply(lambda x:np.std(x),axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
